# Character-Level Language Modeling

## Overview
This project involves building a character-level language model using recurrent neural networks (RNNs) and LSTMs. The models are trained on the Shakespeare dataset to generate text.

## Files
- `dataset.py`: Contains the `TextDataset` class for preprocessing the text data and creating data loaders.
- `model.py`: Contains the implementation of the `VanillaRNN` and `LSTM` models.
- `main.py`: Trains the models and plots the training losses.
- `generate.py`: Uses the trained models to generate text based on a seed character and temperature setting.
- `README.md`: This report file.

## Training and Validation Losses
The following plot shows the training losses for both the Vanilla RNN and LSTM models:

![Training Losses](training_losses.png)

## Text Generation
The following are samples of text generated by the models:

### Vanilla RNN
- Seed: 'H', Temperature: 1.0
